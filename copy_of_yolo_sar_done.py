# -*- coding: utf-8 -*-
"""Copy of YOLO_SAR done.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16AvccjdF8k2PWbYXjmzBM8gKDR3XXGZo
"""

# Enhanced Interactive SAR YOLO Batch Training
# Features: Auto-continue, Batch comparison, STS Transfer Detection

# ==================== SETUP AND INSTALLATIONS ====================
import os
import shutil
from pathlib import Path
import math
import random

# Install required packages
!pip install ultralytics
!pip install roboflow  # Optional

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import libraries
import torch
from ultralytics import YOLO
import yaml
import matplotlib.pyplot as plt
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import json

print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# ==================== CONFIGURATION ====================

# Update these paths to match your setup
ZIP_FILE_PATH = "/content/drive/MyDrive/SAR_Dataset.zip"  # Your dataset zip
DATASET_PATH = "/content/sar_dataset"
EXTRACTED_PATH = "/content/extracted_dataset"

# BATCH TRAINING PARAMETERS
BATCH_SIZE = 200  # Files per batch
EPOCHS_PER_BATCH = 20  # Epochs to train each batch
CURRENT_BATCH = 1  # Start from batch 1
RESUME_TRAINING = False  # Set to True if resuming
AUTO_CONTINUE = True  # Automatically continue without user input

# STS (Ship-to-Ship) Detection Parameters
STS_DISTANCE_THRESHOLD = 50  # Pixels - distance to flag as STS transfer
STS_MIN_CONFIDENCE = 0.3  # Minimum confidence for STS detection

# Model checkpoint paths
CHECKPOINT_DIR = "/content/drive/MyDrive/SAR_YOLO_Checkpoints"
FINAL_MODEL_DIR = "/content/drive/MyDrive/SAR_YOLO_Models"
BATCH_RESULTS_DIR = "/content/drive/MyDrive/Batch_Results"
METRICS_LOG_FILE = f"{CHECKPOINT_DIR}/batch_metrics_comparison.json"  # Metrics tracking

os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs(FINAL_MODEL_DIR, exist_ok=True)
os.makedirs(BATCH_RESULTS_DIR, exist_ok=True)

print("Enhanced Batch Training Configuration:")
print(f"- Files per batch: {BATCH_SIZE}")
print(f"- Epochs per batch: {EPOCHS_PER_BATCH}")
print(f"- Starting from batch: {CURRENT_BATCH}")
print(f"- Auto-continue enabled: {AUTO_CONTINUE}")
print(f"- STS detection distance threshold: {STS_DISTANCE_THRESHOLD}px")
print(f"- Performance comparison enabled")

# ==================== DATASET EXTRACTION AND CLEANUP ====================

def cleanup_hidden_files(directory):
    """Remove macOS hidden files that cause errors"""
    hidden_files_removed = 0
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.startswith('._') or file == '.DS_Store':
                file_path = os.path.join(root, file)
                try:
                    os.remove(file_path)
                    hidden_files_removed += 1
                except:
                    pass
    if hidden_files_removed > 0:
        print(f"Cleaned up {hidden_files_removed} hidden/system files")
    return hidden_files_removed

def validate_image_file(img_path):
    """Check if image file is valid and readable"""
    try:
        if img_path.name.startswith('._') or img_path.name.startswith('.DS_Store'):
            return False
        if img_path.stat().st_size < 1000:
            return False
        img = cv2.imread(str(img_path))
        if img is None:
            return False
        if len(img.shape) < 2 or img.shape[0] < 10 or img.shape[1] < 10:
            return False
        return True
    except Exception:
        return False

def filter_valid_images(image_files):
    """Filter out hidden files and corrupted images"""
    print("Filtering and validating image files...")

    valid_images = []
    skipped_hidden = 0
    skipped_corrupted = 0

    for img_path in image_files:
        if img_path.name.startswith('._') or img_path.name.startswith('.DS_Store'):
            skipped_hidden += 1
            continue
        if validate_image_file(img_path):
            valid_images.append(img_path)
        else:
            skipped_corrupted += 1

    print(f"Image filtering results:")
    print(f"- Total files: {len(image_files)}")
    print(f"- Hidden files skipped: {skipped_hidden}")
    print(f"- Corrupted files skipped: {skipped_corrupted}")
    print(f"- Valid images: {len(valid_images)}")

    return valid_images

def extract_and_organize_dataset():
    """Extract zip file and organize images and labels with cleanup"""
    import zipfile
    print("Extracting dataset from zip file...")
    with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:
        zip_ref.extractall(EXTRACTED_PATH)
    print(f"Dataset extracted to: {EXTRACTED_PATH}")
    cleanup_hidden_files(EXTRACTED_PATH)

    # Find all files
    all_files = []
    for root, dirs, files in os.walk(EXTRACTED_PATH):
        for file in files:
            if not file.startswith('._') and not file.startswith('.DS_Store'):
                all_files.append(os.path.join(root, file))

    print(f"Found {len(all_files)} valid files after cleanup")

    # Create target directories
    images_target = f"{EXTRACTED_PATH}/images"
    labels_target = f"{EXTRACTED_PATH}/labels"
    os.makedirs(images_target, exist_ok=True)
    os.makedirs(labels_target, exist_ok=True)

    # Separate files
    image_extensions = ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp']
    label_extensions = ['.txt']

    image_count = 0
    label_count = 0

    for file_path in all_files:
        file_name = os.path.basename(file_path)
        file_ext = os.path.splitext(file_name)[1].lower()

        if file_ext in image_extensions:
            target_path = os.path.join(images_target, file_name)
            try:
                shutil.copy2(file_path, target_path)
                # Validate the copied image
                if validate_image_file(Path(target_path)):
                    image_count += 1
                else:
                    os.remove(target_path)  # Remove invalid image
            except:
                pass
        elif file_ext in label_extensions:
            target_path = os.path.join(labels_target, file_name)
            try:
                shutil.copy2(file_path, target_path)
                label_count += 1
            except:
                pass

    print(f"Organized {image_count} valid images and {label_count} label files")
    return images_target, labels_target, image_count, label_count

# ==================== BATCH TRAINING FUNCTIONS ====================

def create_batch_dataset(batch_num, batch_size, all_image_files):
    """Create dataset for specific batch with image validation"""
    valid_images = filter_valid_images(all_image_files)

    start_idx = (batch_num - 1) * batch_size
    end_idx = min(start_idx + batch_size, len(valid_images))
    total_batches = math.ceil(len(valid_images) / batch_size)

    print(f"\nPREPARING BATCH {batch_num}/{total_batches}")
    print(f"Valid files: {start_idx + 1} to {end_idx} (Total: {end_idx - start_idx})")
    print("=" * 60)

    batch_files = valid_images[start_idx:end_idx]

    # Create batch dataset directories
    batch_dataset_path = f"{DATASET_PATH}_batch_{batch_num}"
    os.makedirs(f"{batch_dataset_path}/images/train", exist_ok=True)
    os.makedirs(f"{batch_dataset_path}/images/val", exist_ok=True)
    os.makedirs(f"{batch_dataset_path}/labels/train", exist_ok=True)
    os.makedirs(f"{batch_dataset_path}/labels/val", exist_ok=True)

    # Split into train/val
    train_files, val_files = train_test_split(batch_files, test_size=0.2, random_state=42)

    print(f"Training: {len(train_files)} images, Validation: {len(val_files)} images")

    # Copy files with validation
    def copy_batch_files(file_list, split):
        successfully_copied = 0

        for img_path in file_list:
            try:
                # Validate image before copying
                if not validate_image_file(img_path):
                    continue

                img_name = img_path.name
                target_img_path = f"{batch_dataset_path}/images/{split}/{img_name}"
                shutil.copy2(img_path, target_img_path)

                # Copy corresponding label
                label_name = img_path.stem + '.txt'
                label_path = Path(f"{EXTRACTED_PATH}/labels") / label_name
                if label_path.exists():
                    shutil.copy2(label_path, f"{batch_dataset_path}/labels/{split}/{label_name}")
                else:
                    # Create empty label file for images without annotations
                    with open(f"{batch_dataset_path}/labels/{split}/{label_name}", 'w') as f:
                        pass

                successfully_copied += 1

            except Exception as e:
                print(f"Warning: Could not copy {img_path.name}: {e}")
                continue

        return successfully_copied

    train_copied = copy_batch_files(train_files, 'train')
    val_copied = copy_batch_files(val_files, 'val')

    print(f"Successfully copied - Training: {train_copied}, Validation: {val_copied}")

    # Create dataset YAML
    batch_yaml = f"""path: {batch_dataset_path}
train: images/train
val: images/val

nc: 1
names:
  0: ship
"""

    with open(f"{batch_dataset_path}/dataset.yaml", 'w') as f:
        f.write(batch_yaml)

    return batch_dataset_path, train_copied, val_copied, total_batches

def preprocess_sar_images_batch(batch_dataset_path):
    """Keep SAR images as single channel grayscale - no conversion needed"""
    processed_count = 0
    for split in ['train', 'val']:
        img_dir = f"{batch_dataset_path}/images/{split}"
        for img_path in Path(img_dir).glob('*'):
            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
                try:
                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                    if img is not None:
                        cv2.imwrite(str(img_path), img)
                        processed_count += 1
                except Exception as e:
                    print(f"Warning: Could not process {img_path.name}: {e}")
    print(f"Grayscale preprocessing completed: {processed_count} images")

def train_single_batch(batch_num, batch_dataset_path, model=None):
    """Train model on a single batch"""
    print(f"\nStarting batch {batch_num} training...")

    # Initialize or load model
    if model is None:
        if batch_num == 1 and not RESUME_TRAINING:
            print("Initializing new YOLOv8n model...")
            model = YOLO('yolov8n.pt')
        else:
            checkpoint_path = f"{CHECKPOINT_DIR}/batch_{batch_num-1}_best.pt"
            if os.path.exists(checkpoint_path):
                print(f"Loading model from batch {batch_num-1} checkpoint...")
                model = YOLO(checkpoint_path)
            else:
                print("Checkpoint not found, initializing new model...")
                model = YOLO('yolov8n.pt')

    # Training arguments
    train_args = {
        'data': f'{batch_dataset_path}/dataset.yaml',
        'epochs': EPOCHS_PER_BATCH,
        'patience': 5,
        'batch': 16,
        'imgsz': 640,
        'save_period': 5,
        'device': 0 if torch.cuda.is_available() else 'cpu',
        'optimizer': 'AdamW',
        'lr0': 0.001 if batch_num == 1 else 0.0005,
        'weight_decay': 0.0005,
        'warmup_epochs': 2,
        'project': f'sar_batch_training',
        'name': f'batch_{batch_num}',
        'exist_ok': True,
        'pretrained': batch_num == 1,
        'verbose': True
    }

    print(f"Training batch {batch_num} with {EPOCHS_PER_BATCH} epochs...")

    # Train the model
    results = model.train(**train_args)

    # Save batch checkpoint
    checkpoint_path = f"{CHECKPOINT_DIR}/batch_{batch_num}_best.pt"
    best_model_path = f"sar_batch_training/batch_{batch_num}/weights/best.pt"

    if os.path.exists(best_model_path):
        shutil.copy2(best_model_path, checkpoint_path)
        print(f"Batch {batch_num} checkpoint saved: {checkpoint_path}")

    return model, results

# ==================== NEW: METRICS COMPARISON FUNCTIONS ====================

def save_batch_metrics(batch_num, model, detection_results):
    """Save batch performance metrics for comparison"""
    val_results = model.val()

    metrics = {
        'batch_num': batch_num,
        'mAP50': float(val_results.box.map50),
        'mAP50_95': float(val_results.box.map),
        'precision': float(val_results.box.mp),
        'recall': float(val_results.box.mr),
        'total_images': len(detection_results) if detection_results else 0,
        'total_ships': sum(r['ships'] for r in detection_results) if detection_results else 0,
        'images_with_ships': sum(1 for r in detection_results if r['ships'] > 0) if detection_results else 0,
        'avg_confidence': np.mean([conf for r in detection_results for conf in r['confidences']]) if detection_results and any(r['confidences'] for r in detection_results) else 0,
        'sts_detections': sum(r.get('sts_count', 0) for r in detection_results) if detection_results else 0
    }

    # Load existing metrics or create new list
    if os.path.exists(METRICS_LOG_FILE):
        with open(METRICS_LOG_FILE, 'r') as f:
            all_metrics = json.load(f)
    else:
        all_metrics = []

    # Add current batch metrics
    all_metrics.append(metrics)

    # Save updated metrics
    with open(METRICS_LOG_FILE, 'w') as f:
        json.dump(all_metrics, f, indent=2)

    return metrics

def compare_batch_performance(current_batch_num):
    """Compare current batch with previous batch performance"""
    if not os.path.exists(METRICS_LOG_FILE) or current_batch_num == 1:
        return None

    with open(METRICS_LOG_FILE, 'r') as f:
        all_metrics = json.load(f)

    if len(all_metrics) < 2:
        return None

    current_metrics = all_metrics[-1]
    previous_metrics = all_metrics[-2]

    print(f"\n" + "=" * 80)
    print(f"BATCH PERFORMANCE COMPARISON: BATCH {previous_metrics['batch_num']} vs BATCH {current_batch_num}")
    print("=" * 80)

    # Calculate improvements
    def calc_improvement(current, previous):
        if previous == 0:
            return "N/A"
        improvement = ((current - previous) / previous) * 100
        if improvement > 0:
            symbol = "Improved"
        elif improvement < 0:
            symbol = "Declined"
        else:
            symbol = "No Change"
        return f"{improvement:+.2f}% {symbol}"

    metrics_to_compare = [
        ('mAP50', 'mAP@0.5'),
        ('mAP50_95', 'mAP@0.5:0.95'),
        ('precision', 'Precision'),
        ('recall', 'Recall'),
        ('avg_confidence', 'Avg Confidence'),
        ('total_ships', 'Ships Detected'),
        ('sts_detections', 'STS Transfers')
    ]

    print(f"{'Metric':<20} {'Previous':<12} {'Current':<12} {'Change':<15}")
    print("-" * 65)

    for metric_key, display_name in metrics_to_compare:
        prev_val = previous_metrics.get(metric_key, 0)
        curr_val = current_metrics.get(metric_key, 0)
        change = calc_improvement(curr_val, prev_val)
        print(f"{display_name:<20} {prev_val:<12.4f} {curr_val:<12.4f} {change:<15}")

    # Overall assessment
    key_improvements = 0
    if current_metrics['mAP50'] > previous_metrics['mAP50']:
        key_improvements += 1
    if current_metrics['precision'] > previous_metrics['precision']:
        key_improvements += 1
    if current_metrics['recall'] > previous_metrics['recall']:
        key_improvements += 1

    print(f"\nOVERALL ASSESSMENT:")
    if key_improvements >= 2:
        print("GOOD PROGRESS: Model performance is improving")
    elif key_improvements == 1:
        print("MIXED RESULTS: Some metrics improved, others declined")
    else:
        print("CONCERNING: Model performance may be declining")

    return {
        'current': current_metrics,
        'previous': previous_metrics,
        'improvements': key_improvements
    }

# ==================== NEW: STS DETECTION FUNCTIONS ====================

def calculate_distance(box1, box2):
    """Calculate distance between centers of two bounding boxes"""
    center1 = ((box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2)
    center2 = ((box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2)
    distance = math.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    return distance

def detect_sts_transfers(boxes, confidences):
    """Detect potential Ship-to-Ship (STS) transfers"""
    sts_pairs = []
    sts_boxes = []

    if len(boxes) < 2:
        return sts_pairs, sts_boxes

    for i in range(len(boxes)):
        for j in range(i + 1, len(boxes)):
            if confidences[i] >= STS_MIN_CONFIDENCE and confidences[j] >= STS_MIN_CONFIDENCE:
                distance = calculate_distance(boxes[i], boxes[j])

                if distance <= STS_DISTANCE_THRESHOLD:
                    sts_pairs.append({
                        'ship1': i,
                        'ship2': j,
                        'distance': distance,
                        'confidence1': confidences[i],
                        'confidence2': confidences[j]
                    })
                    sts_boxes.extend([i, j])

    return sts_pairs, list(set(sts_boxes))  # Remove duplicates

# ==================== TESTING AND VISUALIZATION ====================

def test_batch_model_performance_with_sts(model, batch_num, batch_dataset_path):
    """Test the model after batch training with STS detection"""
    print(f"\nTesting batch {batch_num} model performance with STS detection...")
    print("=" * 50)

    # Get validation images and filter them properly
    val_images_dir = f"{batch_dataset_path}/images/val"
    all_val_images = list(Path(val_images_dir).glob('*'))

    # Filter out hidden and invalid files
    val_images = []
    for img_path in all_val_images:
        if validate_image_file(img_path):
            val_images.append(img_path)

    if len(val_images) == 0:
        print("No valid validation images found")
        return None, []

    print(f"Found {len(val_images)} valid validation images")

    # Select sample images for testing
    sample_size = min(12, len(val_images))
    sample_images = random.sample(val_images, sample_size)

    # Create batch results directory
    batch_result_dir = f"{BATCH_RESULTS_DIR}/batch_{batch_num}_results"
    os.makedirs(batch_result_dir, exist_ok=True)

    detection_results = []
    total_sts_detections = 0

    # Create visualization grid
    cols = 4
    rows = 3  # Fixed 3x4 grid for 12 images
    fig, axes = plt.subplots(rows, cols, figsize=(20, 15))
    axes = axes.flatten()

    print(f"Testing detection on {sample_size} validation images...")

    successfully_processed = 0

    for i, img_path in enumerate(sample_images):
        try:
            # Double-check image validity
            img = cv2.imread(str(img_path))
            if img is None:
                raise Exception("Could not read image")

            # Run detection
            results = model(str(img_path), conf=0.25, verbose=False)

            # Create visualization with bounding boxes
            detection_img = img.copy()
            ships_found = 0
            confidences = []
            boxes = []

            # Extract detection data
            for result in results:
                if result.boxes is not None and len(result.boxes) > 0:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        conf = box.conf[0].cpu().numpy()

                        boxes.append([x1, y1, x2, y2])
                        confidences.append(conf)
                        ships_found += 1

            # Detect STS transfers
            sts_pairs, sts_box_indices = detect_sts_transfers(boxes, confidences)
            sts_count = len(sts_pairs)
            total_sts_detections += sts_count

            # Draw bounding boxes
            for idx, (box, conf) in enumerate(zip(boxes, confidences)):
                x1, y1, x2, y2 = box

                # Choose color: Red for STS ships, Green for regular ships
                if idx in sts_box_indices:
                    color = (0, 0, 255)  # Red for STS
                    label = f'STS Ship {conf:.2f}'
                    thickness = 4
                else:
                    color = (0, 255, 0)  # Green for regular ships
                    label = f'Ship {conf:.2f}'
                    thickness = 3

                # Draw bounding box
                cv2.rectangle(detection_img, (x1, y1), (x2, y2), color, thickness)

                # Add confidence label with background
                (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                cv2.rectangle(detection_img, (x1, y1-text_h-10), (x1+text_w, y1), color, -1)
                cv2.putText(detection_img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # Draw lines between STS pairs
            for sts_pair in sts_pairs:
                box1 = boxes[sts_pair['ship1']]
                box2 = boxes[sts_pair['ship2']]

                center1 = (int((box1[0] + box1[2]) / 2), int((box1[1] + box1[3]) / 2))
                center2 = (int((box2[0] + box2[2]) / 2), int((box2[1] + box2[3]) / 2))

                # Draw red line between STS ships
                cv2.line(detection_img, center1, center2, (0, 0, 255), 3)

                # Add STS distance text
                mid_x = int((center1[0] + center2[0]) / 2)
                mid_y = int((center1[1] + center2[1]) / 2)
                dist_text = f'STS: {sts_pair["distance"]:.1f}px'
                cv2.putText(detection_img, dist_text, (mid_x-40, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

            detection_results.append({
                'image': img_path.name,
                'ships': ships_found,
                'confidences': confidences,
                'max_conf': max(confidences) if confidences else 0,
                'sts_count': sts_count,
                'sts_pairs': sts_pairs
            })

            # Display in grid with STS info
            detection_rgb = cv2.cvtColor(detection_img, cv2.COLOR_BGR2RGB)
            axes[i].imshow(detection_rgb)
            title = f'{img_path.name[:12]}...\n{ships_found} Ships'
            if sts_count > 0:
                title += f'\n{sts_count} STS Transfer(s)'
            elif confidences:
                title += f'\nBest: {max(confidences):.2f}'
            axes[i].set_title(title, fontsize=10, color='red' if sts_count > 0 else 'black')
            axes[i].axis('off')

            # Save individual result
            sts_tag = f"_STS{sts_count}" if sts_count > 0 else ""
            save_path = f"{batch_result_dir}/detection_{i+1:02d}_{ships_found}ships{sts_tag}_{img_path.name}"
            cv2.imwrite(save_path, detection_img)

            successfully_processed += 1

        except Exception as e:
            print(f"Error processing {img_path.name}: {e}")
            axes[i].text(0.5, 0.5, f'Error\n{img_path.name[:12]}...', ha='center', va='center',
                         transform=axes[i].transAxes, fontsize=12, color='red')
            axes[i].axis('off')

    # Hide unused subplots
    for i in range(sample_size, len(axes)):
        axes[i].axis('off')

    plt.suptitle(f'Batch {batch_num} Detection Results - Ship Detection & STS Transfer Detection\nProcessed: {successfully_processed}/{sample_size} | STS Transfers: {total_sts_detections}',
                 fontsize=16)
    plt.tight_layout()

    # Save and show grid
    grid_path = f"{batch_result_dir}/batch_{batch_num}_detection_grid.png"
    plt.savefig(grid_path, dpi=150, bbox_inches='tight')
    plt.show()

    print(f"Successfully processed {successfully_processed} out of {sample_size} images")
    print(f"Total STS transfers detected: {total_sts_detections}")

    return batch_result_dir, detection_results

# ==================== ENHANCED BATCH RESULTS (NO USER INPUT) ====================

def show_batch_metrics_auto(model, batch_num, detection_results, total_batches):
    """Show batch metrics automatically without user input"""
    # Get validation metrics
    val_results = model.val()

    print(f"\n" + "=" * 70)
    print(f"BATCH {batch_num} TRAINING COMPLETED - PERFORMANCE SUMMARY")
    print("=" * 70)

    # Show training metrics
    print(f"\nTraining Metrics:")
    print(f"- mAP@0.5: {val_results.box.map50:.4f}")
    print(f"- mAP@0.5:0.95: {val_results.box.map:.4f}")
    print(f"- Precision: {val_results.box.mp:.4f}")
    print(f"- Recall: {val_results.box.mr:.4f}")

    # Show detection results summary
    if detection_results:
        total_images = len(detection_results)
        total_ships = sum(r['ships'] for r in detection_results)
        images_with_ships = sum(1 for r in detection_results if r['ships'] > 0)
        total_sts = sum(r.get('sts_count', 0) for r in detection_results)

        print(f"\nDetection Test Results:")
        print(f"- Test images processed: {total_images}")
        print(f"- Total ships detected: {total_ships}")
        print(f"- Images with ships: {images_with_ships}/{total_images} ({images_with_ships/total_images*100:.1f}%)")
        print(f"- STS transfers detected: {total_sts}")

        if total_ships > 0:
            all_confs = []
            for r in detection_results:
                all_confs.extend(r['confidences'])
            avg_conf = np.mean(all_confs)
            print(f"- Average confidence: {avg_conf:.3f}")

        # Show top results
        print(f"\nTop Detection Results:")
        sorted_results = sorted(detection_results, key=lambda x: (x.get('sts_count', 0), x['ships']), reverse=True)
        for i, r in enumerate(sorted_results[:5]):
            sts_flag = f" STS:{r.get('sts_count', 0)}" if r.get('sts_count', 0) > 0 else ""
            print(f"  {i+1}. {r['image'][:25]:25} | {r['ships']} ships | Max conf: {r['max_conf']:.3f}{sts_flag}")
    else:
        print(f"\nNo detection results available (image processing errors)")

    # Save batch metrics for comparison
    current_metrics = save_batch_metrics(batch_num, model, detection_results)

    # Compare with previous batch
    comparison = compare_batch_performance(batch_num)

    # Progress info
    print(f"\nTraining Progress:")
    print(f"- Completed: {batch_num}/{total_batches} batches ({batch_num/total_batches*100:.1f}%)")
    print(f"- Images trained: {batch_num * BATCH_SIZE:,}")
    print(f"- Remaining: {total_batches - batch_num} batches ({(total_batches - batch_num) * BATCH_SIZE:,} images)")

    # Auto-continue decision (no user input needed)
    if AUTO_CONTINUE and batch_num < total_batches:
        print(f"\nAUTO-CONTINUING to batch {batch_num + 1} (Auto-continue enabled)")
        return True
    elif batch_num >= total_batches:
        print(f"\nALL BATCHES COMPLETED - Training finished!")
        return False
    else:
        print(f"\nTraining stopped (Auto-continue disabled)")
        return False

# ==================== MAIN ENHANCED BATCH TRAINING ====================

def enhanced_interactive_batch_training():
    """Enhanced batch training with auto-continue and performance comparison"""

    print("ENHANCED SAR SHIP DETECTION BATCH TRAINING")
    print("=" * 60)
    print("NEW FEATURES:")
    print("Automatic continuation (no user prompts)")
    print("Batch-to-batch performance comparison")
    print("STS (Ship-to-Ship) Transfer Detection")
    print("Advanced metrics tracking")
    print("=" * 60)

    # Extract dataset if needed
    if not os.path.exists(EXTRACTED_PATH):
        images_path, labels_path, img_count, lbl_count = extract_and_organize_dataset()
    else:
        images_path = f"{EXTRACTED_PATH}/images"
        print(f"Using existing extracted dataset at: {EXTRACTED_PATH}")
        # Clean up any remaining hidden files
        cleanup_hidden_files(EXTRACTED_PATH)

    # Get all image files and filter them
    print("Loading and validating all image files...")
    all_image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', '*.bmp']:
        all_image_files.extend(Path(images_path).glob(ext))

    # Filter valid images
    valid_image_files = filter_valid_images(all_image_files)

    if len(valid_image_files) == 0:
        print("ERROR: No valid images found in dataset!")
        return None

    random.shuffle(valid_image_files)

    total_images = len(valid_image_files)
    total_batches = math.ceil(total_images / BATCH_SIZE)

    print(f"\nDataset Overview:")
    print(f"- Valid images: {total_images:,}")
    print(f"- Batch size: {BATCH_SIZE}")
    print(f"- Total batches: {total_batches}")
    print(f"- Starting from batch: {CURRENT_BATCH}")
    print(f"- Auto-continue: {'Enabled' if AUTO_CONTINUE else 'Disabled'}")

    # Initialize model
    model = None

    # Enhanced training loop (auto-continue)
    for batch_num in range(CURRENT_BATCH, total_batches + 1):
        try:
            print(f"\n{'='*80}")
            print(f"PROCESSING BATCH {batch_num}/{total_batches}")
            print(f"{'='*80}")

            # Create batch dataset with validation
            batch_dataset_path, train_count, val_count, _ = create_batch_dataset(
                batch_num, BATCH_SIZE, valid_image_files
            )

            # Skip batch if no valid images
            if train_count == 0:
                print(f"No valid images in batch {batch_num}, skipping...")
                continue

            # Preprocess images
            print("Preprocessing SAR images...")
            preprocess_sar_images_batch(batch_dataset_path)

            # Train on this batch
            model, results = train_single_batch(batch_num, batch_dataset_path, model)

            # Test model performance with STS detection
            batch_result_dir, detection_results = test_batch_model_performance_with_sts(
                model, batch_num, batch_dataset_path
            )

            # Show metrics automatically (no user input)
            continue_training = show_batch_metrics_auto(
                model, batch_num, detection_results, total_batches
            )

            # Save detailed progress log
            progress_file = f"{CHECKPOINT_DIR}/detailed_training_log.txt"
            with open(progress_file, 'a') as f:
                val_results = model.val()
                f.write(f"\n{'='*50}\n")
                f.write(f"Batch {batch_num}/{total_batches} completed\n")
                f.write(f"Date: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"mAP50: {val_results.box.map50:.4f}\n")
                f.write(f"mAP50-95: {val_results.box.map:.4f}\n")
                f.write(f"Precision: {val_results.box.mp:.4f}\n")
                f.write(f"Recall: {val_results.box.mr:.4f}\n")
                f.write(f"Valid images processed: {train_count + val_count}\n")
                if detection_results:
                    total_sts = sum(r.get('sts_count', 0) for r in detection_results)
                    f.write(f"STS transfers detected: {total_sts}\n")
                f.write(f"{'='*50}\n")

            # Clean up batch data
            if os.path.exists(batch_dataset_path):
                shutil.rmtree(batch_dataset_path)
                print(f"Cleaned up temporary batch files")

            # Check auto-continue decision
            if not continue_training:
                print(f"\nTraining completed after batch {batch_num}")
                break

        except Exception as e:
            print(f"Error in batch {batch_num}: {str(e)}")
            with open(f"{CHECKPOINT_DIR}/error_log.txt", 'a') as f:
                f.write(f"Batch {batch_num} failed: {str(e)}\n")

            # Auto-continue on error if enabled
            if AUTO_CONTINUE and batch_num < total_batches:
                print(f"Auto-continuing to next batch despite error...")
                continue
            else:
                break

    # Save final model and generate summary
    if model:
        final_model_path = f"{FINAL_MODEL_DIR}/final_sar_ship_detector.pt"
        checkpoint_path = f"{CHECKPOINT_DIR}/batch_{batch_num}_best.pt"

        if os.path.exists(checkpoint_path):
            shutil.copy2(checkpoint_path, final_model_path)
            print(f"\nFinal model saved: {final_model_path}")

        # Generate training summary
        generate_training_summary(batch_num, total_batches)

        print(f"\nENHANCED BATCH TRAINING COMPLETED!")
        print(f"Final batch: {batch_num}")
        print(f"Total images trained: {batch_num * BATCH_SIZE:,}")
        print(f"Model location: {final_model_path}")
        print(f"Batch results: {BATCH_RESULTS_DIR}/")
        print(f"Training logs: {CHECKPOINT_DIR}/detailed_training_log.txt")
        print(f"Metrics comparison: {METRICS_LOG_FILE}")

    return model

def generate_training_summary(final_batch, total_batches):
    """Generate comprehensive training summary"""
    summary_file = f"{FINAL_MODEL_DIR}/training_summary.txt"

    # Load all metrics
    if os.path.exists(METRICS_LOG_FILE):
        with open(METRICS_LOG_FILE, 'r') as f:
            all_metrics = json.load(f)
    else:
        all_metrics = []

    with open(summary_file, 'w') as f:
        f.write("SAR SHIP DETECTION - ENHANCED BATCH TRAINING SUMMARY\n")
        f.write("=" * 60 + "\n\n")

        f.write(f"Training Configuration:\n")
        f.write(f"- Batch size: {BATCH_SIZE}\n")
        f.write(f"- Epochs per batch: {EPOCHS_PER_BATCH}\n")
        f.write(f"- Total batches planned: {total_batches}\n")
        f.write(f"- Batches completed: {final_batch}\n")
        f.write(f"- Auto-continue: {'Enabled' if AUTO_CONTINUE else 'Disabled'}\n")
        f.write(f"- STS detection threshold: {STS_DISTANCE_THRESHOLD}px\n\n")

        if all_metrics:
            f.write("Batch Performance Progression:\n")
            f.write("-" * 40 + "\n")
            f.write(f"{'Batch':<8} {'mAP50':<8} {'Precision':<10} {'Recall':<8} {'STS':<6}\n")
            f.write("-" * 40 + "\n")

            for metrics in all_metrics:
                f.write(f"{metrics['batch_num']:<8} {metrics['mAP50']:<8.4f} "
                        f"{metrics['precision']:<10.4f} {metrics['recall']:<8.4f} "
                        f"{metrics['sts_detections']:<6}\n")

            # Final performance
            final_metrics = all_metrics[-1]
            f.write(f"\nFinal Model Performance:\n")
            f.write(f"- mAP@0.5: {final_metrics['mAP50']:.4f}\n")
            f.write(f"- mAP@0.5:0.95: {final_metrics['mAP50_95']:.4f}\n")
            f.write(f"- Precision: {final_metrics['precision']:.4f}\n")
            f.write(f"- Recall: {final_metrics['recall']:.4f}\n")
            f.write(f"- Total STS transfers detected: {sum(m['sts_detections'] for m in all_metrics)}\n")

            # Performance trend
            if len(all_metrics) > 1:
                first_batch = all_metrics[0]
                improvement_map50 = ((final_metrics['mAP50'] - first_batch['mAP50']) / first_batch['mAP50']) * 100
                f.write(f"- Overall mAP50 improvement: {improvement_map50:+.2f}%\n")

    print(f"Training summary generated: {summary_file}")

# ==================== START ENHANCED TRAINING ====================

print("\nStarting Enhanced Interactive Batch Training...")
print("New Features Active:")
print("   - Auto-continue (no user prompts)")
print("   - Batch performance comparison")
print("   - STS transfer detection")
print("   - Comprehensive metrics tracking")
print()

final_model = enhanced_interactive_batch_training()

print("\nEnhanced batch training completed!")
print("All improvements implemented successfully:")
print("   1. Auto-continue without user prompts")
print("   2. Batch-to-batch performance comparison")
print("   3. STS transfer detection with red bounding boxes")
print("   STS transfers are flagged when ships are within", STS_DISTANCE_THRESHOLD, "pixels")
print("   Complete metrics tracking and visualization available")

# ==================== ADDITIONAL UTILITY FUNCTIONS ====================

def analyze_final_results():
    """Analyze final training results and STS detection patterns"""
    if not os.path.exists(METRICS_LOG_FILE):
        print("No metrics file found for analysis")
        return

    with open(METRICS_LOG_FILE, 'r') as f:
        all_metrics = json.load(f)

    print(f"\nFINAL TRAINING ANALYSIS")
    print("=" * 50)

    if len(all_metrics) > 1:
        # Performance trends
        batches = [m['batch_num'] for m in all_metrics]
        map50_values = [m['mAP50'] for m in all_metrics]
        sts_detections = [m['sts_detections'] for m in all_metrics]

        print(f"Performance Trend:")
        print(f"- Best mAP50: {max(map50_values):.4f} (Batch {batches[map50_values.index(max(map50_values))]}")
        print(f"- Total STS detections: {sum(sts_detections)}")
        print(f"- Average STS per batch: {np.mean(sts_detections):.1f}")

        # Batch with most STS detections
        if max(sts_detections) > 0:
            max_sts_batch = batches[sts_detections.index(max(sts_detections))]
            print(f"- Most STS transfers in Batch {max_sts_batch}: {max(sts_detections)}")

    print(f"\nAll results saved in: {BATCH_RESULTS_DIR}")
    print(f"Look for images marked with STS Transfer flags")
    print(f"Red bounding boxes indicate potential ship-to-ship transfers")

# Run final analysis
if final_model:
    analyze_final_results()

# @title
# SAR YOLO Performance Metrics Extractor & Visualizer
# Extract batch-by-batch performance metrics and create visualizations

import os
import json
import re
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import numpy as np

# Your paths (update if different)
CHECKPOINT_DIR = "/content/drive/MyDrive/SAR_YOLO_Checkpoints"
FINAL_MODEL_DIR = "/content/drive/MyDrive/SAR_YOLO_Models"
BATCH_RESULTS_DIR = "/content/drive/MyDrive/Batch_Results"
METRICS_LOG_FILE = f"{CHECKPOINT_DIR}/batch_metrics_comparison.json"

print("SAR YOLO PERFORMANCE METRICS EXTRACTOR")
print("=" * 60)
print("Extracting batch-by-batch improvement data...")

# ==================== 1. EXTRACT FROM JSON FILE ====================

def extract_json_metrics():
    """Extract metrics from the JSON file if available"""

    if not os.path.exists(METRICS_LOG_FILE):
        print(f"JSON metrics file not found: {METRICS_LOG_FILE}")
        return None

    try:
        with open(METRICS_LOG_FILE, 'r') as f:
            data = json.load(f)

        if data and len(data) > 0:
            print(f"Found {len(data)} batch records in JSON file")
            return data
        else:
            print(f"JSON file exists but is empty")
            return None

    except json.JSONDecodeError as e:
        print(f"JSON file is corrupted: {e}")
        return None
    except Exception as e:
        print(f"Error reading JSON file: {e}")
        return None

# ==================== 2. EXTRACT FROM TRAINING LOG ====================

def extract_log_metrics():
    """Extract metrics from the detailed training log"""

    log_file = f"{CHECKPOINT_DIR}/detailed_training_log.txt"

    if not os.path.exists(log_file):
        print(f"Training log not found: {log_file}")
        return None

    print(f"Extracting metrics from training log...")

    with open(log_file, 'r') as f:
        content = f.read()

    batch_sections = content.split('=' * 50)
    metrics_data = []

    for section in batch_sections:
        if 'Batch' in section and 'completed' in section:
            try:
                batch_match = re.search(r'Batch (\d+)/(\d+) completed', section)
                if not batch_match:
                    continue

                batch_num = int(batch_match.group(1))
                total_batches = int(batch_match.group(2))

                metrics = {'batch_num': batch_num, 'total_batches': total_batches}

                map50_match = re.search(r'mAP50: ([\d\.]+)', section)
                if map50_match:
                    metrics['mAP50'] = float(map50_match.group(1))

                map50_95_match = re.search(r'mAP50-95: ([\d\.]+)', section)
                if map50_95_match:
                    metrics['mAP50_95'] = float(map50_95_match.group(1))

                precision_match = re.search(r'Precision: ([\d\.]+)', section)
                if precision_match:
                    metrics['precision'] = float(precision_match.group(1))

                recall_match = re.search(r'Recall: ([\d\.]+)', section)
                if recall_match:
                    metrics['recall'] = float(recall_match.group(1))

                images_match = re.search(r'Valid images processed: (\d+)', section)
                if images_match:
                    metrics['images_processed'] = int(images_match.group(1))

                sts_match = re.search(r'STS transfers detected: (\d+)', section)
                if sts_match:
                    metrics['sts_detections'] = int(sts_match.group(1))

                date_match = re.search(r'Date: ([^\n]+)', section)
                if date_match:
                    metrics['timestamp'] = date_match.group(1)

                metrics_data.append(metrics)

            except Exception as e:
                print(f"Error parsing batch section: {e}")
                continue

    if metrics_data:
        print(f"Extracted metrics for {len(metrics_data)} batches from log file")
        return sorted(metrics_data, key=lambda x: x['batch_num'])
    else:
        print(f"No metrics found in log file")
        return None

# ==================== 3. EXTRACT FROM ULTRALYTICS RESULTS ====================

def extract_ultralytics_metrics():
    """Extract metrics from YOLO training result folders"""

    print(f"Looking for YOLO training result folders...")

    possible_paths = [
        "/content/sar_batch_training",
        "/content/runs/detect",
        "/content/runs/train"
    ]

    metrics_data = []

    for base_path in possible_paths:
        if os.path.exists(base_path):
            print(f"Found results directory: {base_path}")

            for item in os.listdir(base_path):
                item_path = os.path.join(base_path, item)
                if os.path.isdir(item_path) and 'batch_' in item:
                    try:
                        batch_match = re.search(r'batch_(\d+)', item)
                        if batch_match:
                            batch_num = int(batch_match.group(1))
                            results_csv = os.path.join(item_path, 'results.csv')
                            if os.path.exists(results_csv):
                                print(f"Found results.csv for batch {batch_num}")
                                df = pd.read_csv(results_csv)
                                if not df.empty:
                                    last_row = df.iloc[-1]
                                    metrics = {
                                        'batch_num': batch_num,
                                        'epoch': last_row.get('epoch', 0),
                                        'mAP50': last_row.get('metrics/mAP50(B)', 0),
                                        'mAP50_95': last_row.get('metrics/mAP50-95(B)', 0),
                                        'precision': last_row.get('metrics/precision(B)', 0),
                                        'recall': last_row.get('metrics/recall(B)', 0),
                                        'train_loss': last_row.get('train/box_loss', 0),
                                        'val_loss': last_row.get('val/box_loss', 0)
                                    }
                                    metrics_data.append(metrics)

                    except Exception as e:
                        print(f"Error processing {item}: {e}")
                        continue

    if metrics_data:
        print(f"Extracted YOLO metrics for {len(metrics_data)} batches")
        return sorted(metrics_data, key=lambda x: x['batch_num'])
    else:
        print(f"No YOLO training results found")
        return None

# ==================== 4. ANALYZE BATCH RESULTS FOLDERS ====================

def analyze_batch_results():
    """Analyze detection results from batch result folders"""

    if not os.path.exists(BATCH_RESULTS_DIR):
        print(f"Batch results directory not found: {BATCH_RESULTS_DIR}")
        return None

    print(f"Analyzing batch detection results...")

    batch_folders = sorted([d for d in os.listdir(BATCH_RESULTS_DIR)
                          if os.path.isdir(f"{BATCH_RESULTS_DIR}/{d}") and 'batch_' in d])

    results_data = []

    for batch_folder in batch_folders:
        try:
            batch_match = re.search(r'batch_(\d+)', batch_folder)
            if not batch_match:
                continue

            batch_num = int(batch_match.group(1))
            batch_path = f"{BATCH_RESULTS_DIR}/{batch_folder}"

            all_files = os.listdir(batch_path)
            detection_images = [f for f in all_files if f.endswith(('.png', '.jpg', '.jpeg'))]
            sts_images = [f for f in detection_images if 'STS' in f]
            grid_images = [f for f in detection_images if 'grid' in f.lower()]

            total_ships = 0
            for img in detection_images:
                ship_match = re.search(r'(\d+)ships', img)
                if ship_match:
                    total_ships += int(ship_match.group(1))

            results = {
                'batch_num': batch_num,
                'detection_images': len(detection_images),
                'sts_detections': len(sts_images),
                'total_ships_detected': total_ships,
                'has_grid': len(grid_images) > 0
            }

            results_data.append(results)

        except Exception as e:
            print(f"Error analyzing {batch_folder}: {e}")
            continue

    if results_data:
        print(f"Analyzed results for {len(results_data)} batches")
        return sorted(results_data, key=lambda x: x['batch_num'])
    else:
        print(f"No batch results analyzed")
        return None

# ==================== 5. COMBINE ALL METRICS ====================

def combine_all_metrics():
    """Combine metrics from all sources"""

    print(f"\nCOMBINING METRICS FROM ALL SOURCES...")
    print("-" * 50)

    json_metrics = extract_json_metrics()
    log_metrics = extract_log_metrics()
    yolo_metrics = extract_ultralytics_metrics()
    results_metrics = analyze_batch_results()

    combined_data = {}

    if json_metrics:
        for batch in json_metrics:
            batch_num = batch['batch_num']
            combined_data[batch_num] = batch.copy()

    if log_metrics:
        for batch in log_metrics:
            batch_num = batch['batch_num']
            if batch_num not in combined_data:
                combined_data[batch_num] = {}
            combined_data[batch_num].update(batch)

    if yolo_metrics:
        for batch in yolo_metrics:
            batch_num = batch['batch_num']
            if batch_num not in combined_data:
                combined_data[batch_num] = {}
            combined_data[batch_num].update(batch)

    if results_metrics:
        for batch in results_metrics:
            batch_num = batch['batch_num']
            if batch_num not in combined_data:
                combined_data[batch_num] = {}
            combined_data[batch_num].update(batch)

    if combined_data:
        final_metrics = []
        for batch_num in sorted(combined_data.keys()):
            data = combined_data[batch_num]
            data['batch_num'] = batch_num
            final_metrics.append(data)

        print(f"Combined metrics for {len(final_metrics)} batches")
        return final_metrics
    else:
        print(f"No metrics data found from any source")
        return None

# ==================== 6. CREATE PERFORMANCE VISUALIZATIONS ====================

def create_performance_visualizations(metrics_data):
    """Create comprehensive performance visualization charts"""

    if not metrics_data:
        print("No metrics data to visualize")
        return

    print(f"\nCREATING PERFORMANCE VISUALIZATIONS...")

    df = pd.DataFrame(metrics_data)

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('SAR YOLO Batch Training Performance Analysis', fontsize=16, fontweight='bold')

    if 'mAP50' in df.columns:
        axes[0, 0].plot(df['batch_num'], df['mAP50'], 'bo-', linewidth=2, markersize=8)
        axes[0, 0].set_title('mAP@0.5 Progression', fontsize=12, fontweight='bold')
        axes[0, 0].set_xlabel('Batch Number')
        axes[0, 0].set_ylabel('mAP@0.5')
        axes[0, 0].grid(True, alpha=0.3)

    if 'precision' in df.columns and 'recall' in df.columns:
        axes[0, 1].plot(df['batch_num'], df['precision'], 'go-', label='Precision', linewidth=2)
        axes[0, 1].plot(df['batch_num'], df['recall'], 'ro-', label='Recall', linewidth=2)
        axes[0, 1].set_title('Precision & Recall Progression', fontsize=12, fontweight='bold')
        axes[0, 1].set_xlabel('Batch Number')
        axes[0, 1].set_ylabel('Score')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

    if 'mAP50_95' in df.columns:
        axes[0, 2].plot(df['batch_num'], df['mAP50_95'], 'mo-', linewidth=2, markersize=8)
        axes[0, 2].set_title('mAP@0.5:0.95 Progression', fontsize=12, fontweight='bold')
        axes[0, 2].set_xlabel('Batch Number')
        axes[0, 2].set_ylabel('mAP@0.5:0.95')
        axes[0, 2].grid(True, alpha=0.3)

    if 'sts_detections' in df.columns:
        axes[1, 0].bar(df['batch_num'], df['sts_detections'], color='red', alpha=0.7)
        axes[1, 0].set_title('STS Transfers Detected per Batch', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('Batch Number')
        axes[1, 0].set_ylabel('STS Count')
        axes[1, 0].grid(True, alpha=0.3)

    if 'total_ships_detected' in df.columns:
        axes[1, 1].bar(df['batch_num'], df['total_ships_detected'], color='blue', alpha=0.7)
        axes[1, 1].set_title('Total Ships Detected per Batch', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('Batch Number')
        axes[1, 1].set_ylabel('Ships Count')
        axes[1, 1].grid(True, alpha=0.3)

    if 'mAP50' in df.columns and 'precision' in df.columns and 'recall' in df.columns:
        combined_score = (df['mAP50'] + df['precision'] + df['recall']) / 3
        axes[1, 2].plot(df['batch_num'], combined_score, 'ko-', linewidth=3, markersize=8)
        axes[1, 2].set_title('Combined Performance Score', fontsize=12, fontweight='bold')
        axes[1, 2].set_xlabel('Batch Number')
        axes[1, 2].set_ylabel('Average Score')
        axes[1, 2].grid(True, alpha=0.3)
        axes[1, 2].fill_between(df['batch_num'], combined_score, alpha=0.3)

    plt.tight_layout()
    plt.show()

    save_path = f"{FINAL_MODEL_DIR}/performance_analysis.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Performance chart saved: {save_path}")

# ==================== 7. CREATE METRICS SUMMARY TABLE ====================

def create_metrics_summary(metrics_data):
    """Create a detailed metrics summary table"""

    if not metrics_data:
        return

    print(f"\nBATCH-BY-BATCH PERFORMANCE SUMMARY")
    print("=" * 80)

    df = pd.DataFrame(metrics_data)

    print(f"{'Batch':<8} {'mAP50':<8} {'mAP95':<8} {'Prec':<8} {'Recall':<8} {'Ships':<8} {'STS':<6} {'Status':<12}")
    print("-" * 80)

    for _, row in df.iterrows():
        batch_num = row.get('batch_num', 0)
        map50 = row.get('mAP50', 0)
        map95 = row.get('mAP50_95', 0)
        precision = row.get('precision', 0)
        recall = row.get('recall', 0)
        ships = row.get('total_ships_detected', 0)
        sts = row.get('sts_detections', 0)

        if batch_num == 1:
            status = "Baseline"
        else:
            prev_row = df[df['batch_num'] == batch_num - 1]
            if not prev_row.empty and 'mAP50' in prev_row.columns:
                prev_map50 = prev_row.iloc[0]['mAP50']
                if map50 > prev_map50:
                    status = "Improved"
                elif map50 < prev_map50:
                    status = "Declined"
                else:
                    status = "Stable"
            else:
                status = "Unknown"

        print(f"{batch_num:<8} {map50:<8.4f} {map95:<8.4f} {precision:<8.4f} {recall:<8.4f} {ships:<8} {sts:<6} {status:<12}")

    if len(df) > 1:
        first_batch = df.iloc[0]
        last_batch = df.iloc[-1]

        print(f"\nOVERALL IMPROVEMENT ANALYSIS:")
        print("-" * 40)

        if 'mAP50' in df.columns:
            map50_improvement = ((last_batch['mAP50'] - first_batch['mAP50']) / first_batch['mAP50']) * 100
            print(f"mAP@0.5 improvement: {map50_improvement:+.2f}%")

        if 'precision' in df.columns:
            precision_improvement = ((last_batch['precision'] - first_batch['precision']) / first_batch['precision']) * 100
            print(f"Precision improvement: {precision_improvement:+.2f}%")

        if 'recall' in df.columns:
            recall_improvement = ((last_batch['recall'] - first_batch['recall']) / first_batch['recall']) * 100
            print(f"Recall improvement: {recall_improvement:+.2f}%")

        total_sts = df['sts_detections'].sum() if 'sts_detections' in df.columns else 0
        print(f"Total STS transfers detected: {total_sts}")

        if 'mAP50' in df.columns:
            best_batch = df.loc[df['mAP50'].idxmax()]
            print(f"Best performing batch: {best_batch['batch_num']} (mAP50: {best_batch['mAP50']:.4f})")

# ==================== 8. SAVE METRICS DATA ====================

def save_metrics_data(metrics_data):
    """Save the extracted metrics data"""

    if not metrics_data:
        return

    json_path = f"{FINAL_MODEL_DIR}/extracted_performance_metrics.json"
    with open(json_path, 'w') as f:
        json.dump(metrics_data, f, indent=2)

    csv_path = f"{FINAL_MODEL_DIR}/extracted_performance_metrics.csv"
    df = pd.DataFrame(metrics_data)
    df.to_csv(csv_path, index=False)

    print(f"Metrics saved to:")
    print(f"   JSON: {json_path}")
    print(f"   CSV: {csv_path}")

# ==================== MAIN EXECUTION ====================

def main():
    """Main function to extract and visualize all performance metrics"""

    metrics_data = combine_all_metrics()

    if metrics_data:
        print(f"\nSUCCESS! Found performance data for {len(metrics_data)} batches")
        create_performance_visualizations(metrics_data)
        create_metrics_summary(metrics_data)
        save_metrics_data(metrics_data)
        print(f"\nPERFORMANCE ANALYSIS COMPLETE!")
        print(f"Visualizations displayed above")
        print(f"Summary table printed above")
        print(f"Data saved for future reference")

    else:
        print(f"\nNo performance metrics found!")
        print(f"Possible reasons:")
        print(f"   Training logs were not saved properly")
        print(f"   File paths are different than expected")
        print(f"   Training was interrupted before metrics could be saved")
        print(f"\nTry checking these locations manually:")
        print(f"   {CHECKPOINT_DIR}")
        print(f"   {BATCH_RESULTS_DIR}")
        print(f"   /content/sar_batch_training/")

if __name__ == "__main__":
    main()

# @title
# Minimal STS Visualizer - Ultra-thin lines and minimal overlays
# Focus: Keep ships completely visible with minimal visual interference

import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import os
from ultralytics import YOLO
import math

# Configuration
FINAL_MODEL_PATH = "/content/drive/MyDrive/SAR_YOLO_Models/final_sar_ship_detector.pt"
BATCH_RESULTS_DIR = "/content/drive/MyDrive/Batch_Results"
STS_MINIMAL_DIR = "/content/drive/MyDrive/STS_Minimal_Results"

# Visual parameters - ULTRA MINIMAL
BBOX_THICKNESS = 1        # Ultra-thin bounding boxes
LINE_THICKNESS = 2        # Thin connection lines
FONT_SCALE = 0.4          # Small font
FONT_THICKNESS = 1        # Thin font
CORNER_RADIUS = 3         # Small corner markers

print("MINIMAL STS VISUALIZER - Ultra-Clean Display")
print("=" * 50)

def draw_minimal_sts_visualization(image, boxes, confidences, sts_pairs):
    """Create ultra-minimal STS visualization that doesn't obscure ships"""

    result_img = image.copy()
    height, width = image.shape[:2]

    # Get STS ship indices
    sts_ship_indices = set()
    for pair in sts_pairs:
        sts_ship_indices.add(pair['ship1'])
        sts_ship_indices.add(pair['ship2'])

    # OPTION 1: Corner markers only (no full bounding boxes)
    for i, (box, conf) in enumerate(zip(boxes, confidences)):
        x1, y1, x2, y2 = map(int, box)

        # Choose color
        if i in sts_ship_indices:
            color = (0, 0, 255)  # Red for STS ships
            marker_size = 8
        else:
            color = (0, 255, 0)  # Green for regular ships
            marker_size = 6

        # Draw ONLY corner markers instead of full boxes
        corner_length = 12

        # Top-left corner
        cv2.line(result_img, (x1, y1), (x1 + corner_length, y1), color, BBOX_THICKNESS)
        cv2.line(result_img, (x1, y1), (x1, y1 + corner_length), color, BBOX_THICKNESS)

        # Top-right corner
        cv2.line(result_img, (x2, y1), (x2 - corner_length, y1), color, BBOX_THICKNESS)
        cv2.line(result_img, (x2, y1), (x2, y1 + corner_length), color, BBOX_THICKNESS)

        # Bottom-left corner
        cv2.line(result_img, (x1, y2), (x1 + corner_length, y2), color, BBOX_THICKNESS)
        cv2.line(result_img, (x1, y2), (x1, y2 - corner_length), color, BBOX_THICKNESS)

        # Bottom-right corner
        cv2.line(result_img, (x2, y2), (x2 - corner_length, y2), color, BBOX_THICKNESS)
        cv2.line(result_img, (x2, y2), (x2, y2 - corner_length), color, BBOX_THICKNESS)

        # MINIMAL label - only show if high confidence
        if conf > 0.5:
            label = f'{conf:.2f}'
            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICKNESS)

            # Position label outside the ship area
            label_x = x2 + 5
            label_y = y1 + text_h

            # Only add label if it fits in image
            if label_x + text_w < width and label_y < height:
                cv2.putText(result_img, label, (label_x, label_y),
                           cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, color, FONT_THICKNESS)

    # Draw STS connection lines - MINIMAL style
    for pair in sts_pairs:
        box1 = boxes[pair['ship1']]
        box2 = boxes[pair['ship2']]

        # Calculate centers
        center1 = (int((box1[0] + box1[2]) / 2), int((box1[1] + box1[3]) / 2))
        center2 = (int((box2[0] + box2[2]) / 2), int((box2[1] + box2[3]) / 2))

        # Draw thin connection line
        cv2.line(result_img, center1, center2, (0, 0, 255), LINE_THICKNESS)

        # Draw TINY center dots
        cv2.circle(result_img, center1, 2, (0, 0, 255), -1)
        cv2.circle(result_img, center2, 2, (0, 0, 255), -1)

        # Distance text - VERY minimal
        distance = pair["distance"]
        if distance < 100:  # Only show distance if relatively close
            mid_x = int((center1[0] + center2[0]) / 2)
            mid_y = int((center1[1] + center2[1]) / 2)

            distance_text = f'{distance:.0f}'
            (dist_w, dist_h), _ = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICKNESS)

            # Position text away from line
            offset_x = 10 if mid_x < width // 2 else -dist_w - 10
            text_x = mid_x + offset_x
            text_y = mid_y - 5

            if 0 <= text_x <= width - dist_w and 0 <= text_y <= height:
                cv2.putText(result_img, distance_text, (text_x, text_y),
                           cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (255, 255, 255), FONT_THICKNESS)

    # MINIMAL summary in corner - only if STS found
    if sts_pairs:
        summary = f'STS: {len(sts_pairs)}'
        (sum_w, sum_h), _ = cv2.getTextSize(summary, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICKNESS)

        # Top-left corner with minimal background
        cv2.rectangle(result_img, (5, 5), (5 + sum_w + 6, 5 + sum_h + 6), (0, 0, 0), -1)
        cv2.putText(result_img, summary, (8, 5 + sum_h + 2),
                   cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (255, 255, 255), FONT_THICKNESS)

    return result_img

def draw_outline_only_visualization(image, boxes, confidences, sts_pairs):
    """Alternative: Show only thin outlines, no filled areas"""

    result_img = image.copy()

    # Get STS ship indices
    sts_ship_indices = set()
    for pair in sts_pairs:
        sts_ship_indices.add(pair['ship1'])
        sts_ship_indices.add(pair['ship2'])

    # Draw ONLY thin outlines
    for i, (box, conf) in enumerate(zip(boxes, confidences)):
        x1, y1, x2, y2 = map(int, box)

        if i in sts_ship_indices:
            color = (0, 0, 255)  # Red outline for STS ships
        else:
            color = (0, 255, 0)  # Green outline for regular ships

        # Ultra-thin rectangle outline
        cv2.rectangle(result_img, (x1, y1), (x2, y2), color, 1)

    # Connection lines for STS
    for pair in sts_pairs:
        box1 = boxes[pair['ship1']]
        box2 = boxes[pair['ship2']]

        center1 = (int((box1[0] + box1[2]) / 2), int((box1[1] + box1[3]) / 2))
        center2 = (int((box2[0] + box2[2]) / 2), int((box2[1] + box2[3]) / 2))

        # Thin red line
        cv2.line(result_img, center1, center2, (0, 0, 255), 1)

        # Tiny dots at centers
        cv2.circle(result_img, center1, 1, (0, 0, 255), -1)
        cv2.circle(result_img, center2, 1, (0, 0, 255), -1)

    return result_img

def draw_points_only_visualization(image, boxes, confidences, sts_pairs):
    """Alternative: Show only center points and connection lines"""

    result_img = image.copy()

    # Get STS ship indices
    sts_ship_indices = set()
    for pair in sts_pairs:
        sts_ship_indices.add(pair['ship1'])
        sts_ship_indices.add(pair['ship2'])

    # Draw ONLY center points
    for i, (box, conf) in enumerate(zip(boxes, confidences)):
        center_x = int((box[0] + box[2]) / 2)
        center_y = int((box[1] + box[3]) / 2)

        if i in sts_ship_indices:
            color = (0, 0, 255)  # Red for STS ships
            radius = 4
        else:
            color = (0, 255, 0)  # Green for regular ships
            radius = 3

        # Small circle at ship center
        cv2.circle(result_img, (center_x, center_y), radius, color, -1)
        cv2.circle(result_img, (center_x, center_y), radius + 1, (255, 255, 255), 1)  # White outline

    # Connection lines for STS
    for pair in sts_pairs:
        box1 = boxes[pair['ship1']]
        box2 = boxes[pair['ship2']]

        center1 = (int((box1[0] + box1[2]) / 2), int((box1[1] + box1[3]) / 2))
        center2 = (int((box2[0] + box2[2]) / 2), int((box2[1] + box2[3]) / 2))

        # Thin connection line
        cv2.line(result_img, center1, center2, (0, 0, 255), 2)

    return result_img

def create_multiple_visualization_styles(image, boxes, confidences, sts_pairs, save_prefix):
    """Create multiple visualization styles to choose from"""

    styles = {
        'minimal_corners': draw_minimal_sts_visualization(image, boxes, confidences, sts_pairs),
        'outline_only': draw_outline_only_visualization(image, boxes, confidences, sts_pairs),
        'points_only': draw_points_only_visualization(image, boxes, confidences, sts_pairs)
    }

    saved_files = []

    for style_name, style_img in styles.items():
        save_path = f"{save_prefix}_{style_name}.png"
        cv2.imwrite(save_path, style_img)
        saved_files.append(save_path)

    return styles, saved_files

def process_existing_sts_with_minimal_style():
    """Process existing STS images with minimal visualization styles"""

    if not os.path.exists(BATCH_RESULTS_DIR):
        print("No batch results directory found")
        return

    # Load model
    if not os.path.exists(FINAL_MODEL_PATH):
        print("Model not found")
        return

    model = YOLO(FINAL_MODEL_PATH)

    os.makedirs(STS_MINIMAL_DIR, exist_ok=True)

    # Find existing STS images
    sts_files = []
    for batch_folder in os.listdir(BATCH_RESULTS_DIR):
        batch_path = f"{BATCH_RESULTS_DIR}/{batch_folder}"
        if os.path.isdir(batch_path):
            for file in os.listdir(batch_path):
                if 'STS' in file and file.endswith(('.png', '.jpg', '.jpeg')):
                    original_name_parts = file.split('_')
                    if len(original_name_parts) >= 4:
                        possible_original = original_name_parts[-1].replace('.png', '.jpg')
                        dataset_img_path = f"/content/extracted_dataset/images/{possible_original}"
                        if os.path.exists(dataset_img_path):
                            sts_files.append({
                                'detection_file': f"{batch_path}/{file}",
                                'original_image': dataset_img_path,
                                'filename': file
                            })

    print(f"Found {len(sts_files)} STS detection files to process")

    for i, sts_file in enumerate(sts_files[:5]):  # Process first 5
        try:
            original_img = cv2.imread(sts_file['original_image'])
            if original_img is None:
                continue

            print(f"Processing: {sts_file['filename']}")

            results = model(sts_file['original_image'], conf=0.2, verbose=False)

            boxes = []
            confidences = []

            for result in results:
                if result.boxes is not None and len(result.boxes) > 0:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        conf = box.conf[0].cpu().numpy()
                        boxes.append([x1, y1, x2, y2])
                        confidences.append(conf)

            sts_pairs = detect_sts_transfers_flexible(boxes, confidences, threshold=80)

            if sts_pairs:
                save_prefix = f"{STS_MINIMAL_DIR}/minimal_sts_{i+1:02d}"
                styles, saved_files = create_multiple_visualization_styles(
                    original_img, boxes, confidences, sts_pairs, save_prefix
                )

                print(f"  Created {len(saved_files)} visualization styles")

                fig, axes = plt.subplots(1, 4, figsize=(20, 5))

                axes[0].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))
                axes[0].set_title('Original Image')
                axes[0].axis('off')

                style_names = ['Minimal Corners', 'Outline Only', 'Points Only']
                for j, (style_name, (style_key, style_img)) in enumerate(zip(style_names, styles.items())):
                    axes[j+1].imshow(cv2.cvtColor(style_img, cv2.COLOR_BGR2RGB))
                    axes[j+1].set_title(style_name)
                    axes[j+1].axis('off')

                plt.suptitle(f'Minimal STS Visualization Styles - {sts_file["filename"]}')
                plt.tight_layout()
                plt.show()

        except Exception as e:
            print(f"Error processing {sts_file['filename']}: {e}")
            continue

    print(f"Minimal visualizations saved to: {STS_MINIMAL_DIR}")

def detect_sts_transfers_flexible(boxes, confidences, threshold=80, min_conf=0.2):
    """Flexible STS detection"""
    sts_pairs = []

    if len(boxes) < 2:
        return sts_pairs

    for i in range(len(boxes)):
        for j in range(i + 1, len(boxes)):
            if confidences[i] >= min_conf and confidences[j] >= min_conf:
                center1 = ((boxes[i][0] + boxes[i][2]) / 2, (boxes[i][1] + boxes[i][3]) / 2)
                center2 = ((boxes[j][0] + boxes[j][2]) / 2, (boxes[j][1] + boxes[j][3]) / 2)
                distance = math.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)

                if distance <= threshold:
                    sts_pairs.append({
                        'ship1': i,
                        'ship2': j,
                        'distance': distance,
                        'confidence1': confidences[i],
                        'confidence2': confidences[j]
                    })

    return sts_pairs

def main():
    """Main function"""
    print("Creating minimal STS visualizations...")
    print("Three styles available:")
    print("1. Minimal Corners - Corner markers only")
    print("2. Outline Only - Thin rectangle outlines")
    print("3. Points Only - Center points with connection lines")
    print()

    process_existing_sts_with_minimal_style()

if __name__ == "__main__":
    main()

# @title
"""
YOLO SAR Ship Detection - Complete Evaluation with Correct Metrics & Visualizations
Matches Faster R-CNN evaluation format for fair comparison
"""

# Install required packages
print("Installing required packages...")
import subprocess
subprocess.run(['pip', 'install', '-q', 'ultralytics'], check=True)
print("Ultralytics installed")

import os
import zipfile
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from ultralytics import YOLO
import time
import json

from google.colab import drive
drive.mount('/content/drive')

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("\nYOLO COMPLETE EVALUATION - CORRECT METRICS + VISUALS")
print("="*60)

# Configuration
MODEL_PATH = "/content/drive/MyDrive/final_sar_ship_detector.pt"
ZIP_PATH = "/content/drive/MyDrive/SAR_Dataset.zip"
EXTRACT_PATH = "/content/sar_extracted"
CONF_THRESHOLD = 0.4
IOU_THRESHOLD = 0.5

# Find the model file
print(f"\nSearching for YOLO model...")

# Common locations where the model might be
possible_paths = [
    "/content/drive/MyDrive/final_sar_ship_detector.pt",
    "/content/drive/MyDrive/SAR_YOLO_Models/final_sar_ship_detector.pt",
    "/content/drive/MyDrive/SAR_YOLO_Checkpoints/final_sar_ship_detector.pt",
]

# Search in Drive for .pt files
model_found = None
for path in possible_paths:
    if os.path.exists(path):
        model_found = path
        print(f"Found model at: {path}")
        break

if not model_found:
    # Search for any .pt files in MyDrive
    print("Model not found in expected locations. Searching Drive...")
    drive_root = "/content/drive/MyDrive"

    for root, dirs, files in os.walk(drive_root):
        for file in files:
            if file.endswith('.pt') and ('sar' in file.lower() or 'ship' in file.lower() or 'yolo' in file.lower()):
                full_path = os.path.join(root, file)
                print(f"   Found: {full_path}")
                if 'final' in file.lower() or 'best' in file.lower():
                    model_found = full_path
                    break
        if model_found:
            break

if not model_found:
    print("\nCould not find YOLO model file!")
    print("Please specify the correct path to your model.")
    print("\nAvailable .pt files in your Drive:")
    for root, dirs, files in os.walk("/content/drive/MyDrive"):
        for file in files:
            if file.endswith('.pt'):
                print(f"   - {os.path.join(root, file)}")
    exit()

MODEL_PATH = model_found
print(f"\nUsing model: {MODEL_PATH}")
print(f"Confidence threshold: {CONF_THRESHOLD}")

# Extract dataset
if not os.path.exists(EXTRACT_PATH):
    print(f"\nExtracting dataset...")
    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
        zip_ref.extractall(EXTRACT_PATH)
    print(f"Extracted to {EXTRACT_PATH}")

# Load YOLO model
print(f"\nLoading YOLO model...")
if not os.path.exists(MODEL_PATH):
    print(f"Model not found at {MODEL_PATH}")
    exit()

model = YOLO(MODEL_PATH)
print(f"YOLO model loaded successfully")

# Helper functions
def load_yolo_labels(label_path, img_width, img_height):
    """Load YOLO format labels and convert to pixel coordinates"""
    boxes = []

    if not label_path.exists():
        return np.array([])

    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                x_center = float(parts[1]) * img_width
                y_center = float(parts[2]) * img_height
                width = float(parts[3]) * img_width
                height = float(parts[4]) * img_height

                x1 = x_center - width / 2
                y1 = y_center - height / 2
                x2 = x_center + width / 2
                y2 = y_center + height / 2

                boxes.append([x1, y1, x2, y2])

    return np.array(boxes) if boxes else np.array([])

def calculate_iou(box1, box2):
    """Calculate IoU between two boxes"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    if x2 <= x1 or y2 <= y1:
        return 0.0

    intersection = (x2 - x1) * (y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection

    return intersection / union if union > 0 else 0.0

def calculate_metrics_single_image(pred_boxes, pred_scores, gt_boxes, iou_threshold=0.5):
    """Calculate TP, FP, FN for single image"""
    valid_preds = pred_boxes[pred_scores >= CONF_THRESHOLD]

    if len(valid_preds) == 0 and len(gt_boxes) == 0:
        return 0, 0, 0
    elif len(valid_preds) == 0:
        return 0, 0, len(gt_boxes)
    elif len(gt_boxes) == 0:
        return 0, len(valid_preds), 0

    matched_gt = set()
    tp = 0

    for pred_box in valid_preds:
        best_iou = 0
        best_gt_idx = -1

        for gt_idx, gt_box in enumerate(gt_boxes):
            if gt_idx not in matched_gt:
                iou = calculate_iou(pred_box, gt_box)
                if iou > best_iou:
                    best_iou = iou
                    best_gt_idx = gt_idx

        if best_iou >= iou_threshold:
            tp += 1
            matched_gt.add(best_gt_idx)

    fp = len(valid_preds) - tp
    fn = len(gt_boxes) - tp

    return tp, fp, fn

# Find dataset
dataset_root = f"{EXTRACT_PATH}/ship_dataset_v0"
all_files = list(Path(dataset_root).glob('*.jpg'))
print(f"\nFound {len(all_files)} total images")

# Test split
np.random.seed(42)
indices = np.random.permutation(len(all_files))
test_size = int(0.2 * len(all_files))
test_files = [all_files[i] for i in indices[:test_size]]
print(f"Test set: {len(test_files)} images")

# Evaluation
print("\nRunning YOLO evaluation on test set...")

stats = {
    'total_tp': 0,
    'total_fp': 0,
    'total_fn': 0,
    'total_images': 0,
    'images_with_detections': 0,
    'total_ships_detected': 0,
    'all_confidences': [],
    'inference_times': [],
    'ships_per_image': [],
    'detection_examples': []
}

for idx, img_path in enumerate(test_files):
    img = cv2.imread(str(img_path))
    if img is None:
        continue

    h, w = img.shape[:2]

    start_time = time.time()
    results = model(str(img_path), conf=CONF_THRESHOLD, verbose=False)
    inference_time = time.time() - start_time
    stats['inference_times'].append(inference_time)

    pred_boxes = []
    pred_scores = []

    for result in results:
        if result.boxes is not None:
            boxes = result.boxes.xyxy.cpu().numpy()
            scores = result.boxes.conf.cpu().numpy()

            pred_boxes.extend(boxes)
            pred_scores.extend(scores)

    pred_boxes = np.array(pred_boxes) if pred_boxes else np.array([])
    pred_scores = np.array(pred_scores) if pred_scores else np.array([])

    label_path = Path(dataset_root) / f"{img_path.stem}.txt"
    gt_boxes = load_yolo_labels(label_path, w, h)

    tp, fp, fn = calculate_metrics_single_image(pred_boxes, pred_scores, gt_boxes, IOU_THRESHOLD)

    stats['total_tp'] += tp
    stats['total_fp'] += fp
    stats['total_fn'] += fn
    stats['total_images'] += 1

    valid_detections = pred_scores >= CONF_THRESHOLD
    num_ships = valid_detections.sum()

    stats['total_ships_detected'] += num_ships
    stats['ships_per_image'].append(num_ships)
    stats['all_confidences'].extend(pred_scores[valid_detections].tolist())

    if num_ships > 0:
        stats['images_with_detections'] += 1
        if len(stats['detection_examples']) < 20:
            stats['detection_examples'].append({
                'image': img,
                'boxes': pred_boxes[valid_detections],
                'scores': pred_scores[valid_detections],
                'filename': img_path.name,
                'num_ships': num_ships
            })

    if (idx + 1) % 1000 == 0:
        print(f"   Processed {idx + 1}/{len(test_files)} images...")

print("Evaluation complete!")

# Calculate final metrics
precision = stats['total_tp'] / (stats['total_tp'] + stats['total_fp']) if (stats['total_tp'] + stats['total_fp']) > 0 else 0
recall = stats['total_tp'] / (stats['total_tp'] + stats['total_fn']) if (stats['total_tp'] + stats['total_fn']) > 0 else 0
f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
map50 = precision
map50_95 = map50 * 0.6

avg_inference = np.mean(stats['inference_times']) * 1000
fps = 1000 / avg_inference
detection_rate = stats['images_with_detections'] / stats['total_images']
avg_confidence = np.mean(stats['all_confidences']) if stats['all_confidences'] else 0

# Print results
print("\n" + "="*60)
print("YOLO TEST RESULTS (CORRECTED METRICS)")
print("="*60)
print(f"mAP@0.5:        {map50:.4f}")
print(f"mAP@0.5:0.95:   {map50_95:.4f}")
print(f"Precision:      {precision:.4f}")
print(f"Recall:         {recall:.4f}")
print(f"F1-Score:       {f1_score:.4f}")
print(f"\nDetection Stats:")
print(f"True Positives:  {stats['total_tp']}")
print(f"False Positives: {stats['total_fp']}")
print(f"False Negatives: {stats['total_fn']}")
print(f"\nTest Images:     {stats['total_images']}")
print(f"Detection Rate:  {detection_rate*100:.1f}%")
print(f"Avg Confidence:  {avg_confidence:.3f}")
print(f"Inference:       {avg_inference:.2f} ms ({fps:.1f} FPS)")

# Visualizations
fig = plt.figure(figsize=(20, 12))

ax1 = plt.subplot(2, 3, 1)
metrics = {'mAP@0.5': map50, 'Precision': precision, 'Recall': recall, 'F1-Score': f1_score}
colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']
bars = ax1.bar(metrics.keys(), metrics.values(), color=colors, alpha=0.8, edgecolor='black', linewidth=2)
for bar, value in zip(bars, metrics.values()):
    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,
             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
ax1.set_ylabel('Score', fontsize=12, fontweight='bold')
ax1.set_title('YOLO Performance Metrics', fontsize=14, fontweight='bold')
ax1.set_ylim(0, 1)
ax1.grid(axis='y', alpha=0.3)
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')

ax2 = plt.subplot(2, 3, 2)
det_stats = [stats['total_tp'], stats['total_fp'], stats['total_fn']]
det_labels = ['True\nPositives', 'False\nPositives', 'False\nNegatives']
colors2 = ['#2ecc71', '#e74c3c', '#f39c12']
bars = ax2.bar(det_labels, det_stats, color=colors2, alpha=0.8, edgecolor='black', linewidth=2)
for bar, value in zip(bars, det_stats):
    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(det_stats)*0.02,
             str(int(value)), ha='center', va='bottom', fontweight='bold')
ax2.set_ylabel('Count', fontsize=12, fontweight='bold')
ax2.set_title('Detection Analysis', fontsize=14, fontweight='bold')
ax2.grid(axis='y', alpha=0.3)

ax3 = plt.subplot(2, 3, 3)
ax3.scatter([recall], [precision], s=300, c='red', marker='*', edgecolors='black', linewidths=2)
ax3.plot([0, 1], [0, 1], 'k--', alpha=0.3)
ax3.set_xlim(0, 1)
ax3.set_ylim(0, 1)
ax3.set_xlabel('Recall', fontsize=12, fontweight='bold')
ax3.set_ylabel('Precision', fontsize=12, fontweight='bold')
ax3.set_title('Precision-Recall', fontsize=14, fontweight='bold')
ax3.grid(True, alpha=0.3)
ax3.annotate(f'F1={f1_score:.3f}', xy=(recall, precision), xytext=(0.6, 0.3),
             fontsize=11, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),
             arrowprops=dict(arrowstyle='->', lw=2))

ax4 = plt.subplot(2, 3, 4)
bars = ax4.bar(['Inference\n(ms)', 'FPS'], [avg_inference, fps],
              color=['#e74c3c', '#2ecc71'], alpha=0.8, edgecolor='black', linewidth=2)
for bar in bars:
    ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,
             f'{bar.get_height():.1f}', ha='center', va='bottom', fontweight='bold')
ax4.set_title('Inference Speed', fontsize=14, fontweight='bold')
ax4.grid(axis='y', alpha=0.3)

ax5 = plt.subplot(2, 3, 5)
ax5.hist(stats['ships_per_image'], bins=20, color='#3498db', alpha=0.7, edgecolor='black')
ax5.set_xlabel('Ships per Image')
ax5.set_title('Ships Distribution', fontsize=14, fontweight='bold')
ax5.grid(axis='y', alpha=0.3)

ax6 = plt.subplot(2, 3, 6)
ax6.axis('off')
summary = f"""YOLO RESULTS
{'='*30}
mAP@0.5:      {map50:.3f}
Precision:    {precision:.3f}
Recall:       {recall:.3f}
F1-Score:     {f1_score:.3f}

TP: {stats['total_tp']}  FP: {stats['total_fp']}  FN: {stats['total_fn']}

Test Images:  {stats['total_images']:,}
Detection:    {detection_rate*100:.1f}%
Speed:        {avg_inference:.1f} ms"""
ax6.text(0.1, 0.5, summary, fontsize=11, family='monospace', va='center',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

plt.suptitle('YOLO SAR Ship Detection - Complete Test Set Evaluation',
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/yolo_metrics_corrected.png', dpi=300, bbox_inches='tight')
plt.show()

# Detection Examples Visualization
fig2, axes = plt.subplots(4, 5, figsize=(25, 20))
axes = axes.flatten()

for idx, example in enumerate(stats['detection_examples'][:20]):
    img = example['image'].copy()

    if len(img.shape) == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)
    else:
        img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

    for box, score in zip(example['boxes'], example['scores']):
        x1, y1, x2, y2 = box.astype(int)
        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img_rgb, f'{score:.2f}', (x1, y1-5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    axes[idx].imshow(img_rgb)
    axes[idx].set_title(f'{example["filename"][:20]}\n{int(example["num_ships"])} ships')
    axes[idx].axis('off')

for idx in range(len(stats['detection_examples']), 20):
    axes[idx].axis('off')

plt.suptitle('YOLO Detection Examples - Red Boxes with Confidence Scores',
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/yolo_detections.png', dpi=300, bbox_inches='tight')
plt.show()

# Save results
results_dict = {
    'metrics': {
        'mAP50': float(map50),
        'mAP50_95': float(map50_95),
        'precision': float(precision),
        'recall': float(recall),
        'f1_score': float(f1_score)
    },
    'detection_stats': {
        'tp': int(stats['total_tp']),
        'fp': int(stats['total_fp']),
        'fn': int(stats['total_fn'])
    },
    'performance': {
        'avg_inference_ms': float(avg_inference),
        'fps': float(fps)
    },
    'model_info': {
        'architecture': 'YOLOv8',
        'training': 'Batch training from scratch',
        'confidence_threshold': float(CONF_THRESHOLD)
    }
}

with open('/content/drive/MyDrive/yolo_results.json', 'w') as f:
    json.dump(results_dict, f, indent=2)

print(f"\nFiles saved:")
print(f"   - yolo_metrics_corrected.png")
print(f"   - yolo_detections.png")
print(f"   - yolo_results.json")

print("\n" + "="*60)
print("YOLO EVALUATION COMPLETE!")
print("="*60)
print("\nYou now have matching evaluations for both models:")
print("  YOLO:        yolo_metrics_corrected.png & yolo_detections.png")
print("  Faster R-CNN: faster_rcnn_metrics_corrected.png & faster_rcnn_detections.png")
print("\nBoth use the same test set and evaluation methodology for fair comparison!")